{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries including the OpenAI gym module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "#from frozen_lake import generate_random_map,FrozenLakeEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a FrozenLake-v0 environment using the `gym.make()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')\n",
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it look like? Basically, a 4x4 grid world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the action size and the total size of the state space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available actions at any state: 4\n",
      "Size of the total state space: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of available actions at any state:\",action_size)\n",
    "print(\"Size of the total state space:\",state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.0, False, {'prob': 0.3333333333333333})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.0, False, {'prob': 0.3333333333333333})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate an empty (filled with zeroes) Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtable = np.zeros((state_size, action_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define some parameters for Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 250\n",
    "learning_rate = 0.8\n",
    "max_steps = 99\n",
    "gamma = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability threshold parameters (for deciding whether to choose the current maximum of the Q-table or to select a complety random one from the action space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Q-learning to fill up the Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for episode in range(total_episodes):\n",
    "    state = env.reset()\n",
    "    total_rewards = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        exp_exp_tradeoff = random.uniform(0, 1)\n",
    "        if exp_exp_tradeoff > epsilon:\n",
    "            action = np.argmax(qtable[state])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Updating Q-table\n",
    "        qtable[state, action] = qtable[state, action] + learning_rate * \\\n",
    "        (reward + gamma * np.max(qtable[new_state]) - qtable[state, action])\n",
    "\n",
    "        state = new_state\n",
    "        total_rewards += reward\n",
    "        if done: break\n",
    "    \n",
    "    # Decaying the epsilon\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate * (episode+1))\n",
    "    rewards.append(total_rewards)\n",
    "\n",
    "    #print('[*] episode {}, total reward {}, \\\n",
    "    #average score {}'.format(episode+1, total_rewards, sum(rewards)/(episode+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the Q function table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.86264015e-02 9.12458605e-02 9.46786422e-02 9.15141219e-02]\n",
      " [2.76554309e-02 7.50391696e-02 4.75262572e-03 7.38726202e-02]\n",
      " [7.70086210e-02 2.27811283e-02 6.81175443e-02 7.10883661e-02]\n",
      " [2.69734556e-02 1.54727310e-02 1.47086572e-02 7.21555355e-02]\n",
      " [1.22940622e-01 5.07195536e-02 2.34023009e-03 1.05384759e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.62946187e-02 6.23308974e-04 3.32817579e-03 1.38906424e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.46545963e-02 8.34212322e-02 1.82322142e-02 3.24048025e-01]\n",
      " [2.76834491e-02 6.44094658e-01 4.07571670e-02 9.69351630e-02]\n",
      " [1.93568435e-01 3.46275003e-02 2.70710172e-03 4.85800458e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.15716414e-01 1.75007630e-01 6.03640158e-01 4.78241644e-01]\n",
      " [6.16145984e-01 6.14232048e-01 5.75909912e-01 8.11702284e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(qtable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a demo of playing a game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "EPISODE  0\n",
      "********************\n",
      "-------------------------\n",
      "Step  0\n",
      "-------------------------\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  1\n",
      "-------------------------\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  2\n",
      "-------------------------\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  3\n",
      "-------------------------\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  4\n",
      "-------------------------\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  5\n",
      "-------------------------\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  6\n",
      "-------------------------\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  7\n",
      "-------------------------\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  8\n",
      "-------------------------\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  9\n",
      "-------------------------\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  10\n",
      "-------------------------\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  11\n",
      "-------------------------\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  12\n",
      "-------------------------\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  13\n",
      "-------------------------\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  14\n",
      "-------------------------\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  15\n",
      "-------------------------\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  16\n",
      "-------------------------\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  17\n",
      "-------------------------\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "-------------------------\n",
      "Step  18\n",
      "-------------------------\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "-------------------------\n",
      "Step  19\n",
      "-------------------------\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "-------------------------\n",
      "Step  20\n",
      "-------------------------\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "-------------------------\n",
      "Step  21\n",
      "-------------------------\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "-------------------------\n",
      "Step  22\n",
      "-------------------------\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "-------------------------\n",
      "Step  23\n",
      "-------------------------\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "-------------------------\n",
      "Step  24\n",
      "-------------------------\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "-------------------------\n",
      "Step  25\n",
      "-------------------------\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  26\n",
      "-------------------------\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "-------------------------\n",
      "Step  27\n",
      "-------------------------\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "-------------------------\n",
      "Step  28\n",
      "-------------------------\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "-------------------------\n",
      "Step  29\n",
      "-------------------------\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n"
     ]
    }
   ],
   "source": [
    "# Play the game\n",
    "for episode in range(1):\n",
    "    state = env.reset()\n",
    "    print('*'*20)\n",
    "    print('EPISODE ', episode)\n",
    "    print('*'*20)\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        print(\"-\"*25)\n",
    "        print(\"Step \",step)\n",
    "        print(\"-\"*25)\n",
    "        env.render()\n",
    "        action = np.argmax(qtable[state])\n",
    "        state, reward, done, info = env.step(action)\n",
    "        if done: break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
